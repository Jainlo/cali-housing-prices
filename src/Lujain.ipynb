{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building\n",
    "### Get clean features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source eda file\n",
    "%run eda_lujain.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting\n",
    "Split the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17994, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# featues\n",
    "X = cali.drop(\"median_house_value\", axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17994,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target variable\n",
    "Y = cali[\"median_house_value\"]\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X, Y, train_size=0.7, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBRegressor\n",
    "XGBRegressor is part of the library XGBoost which stands for \"Extreme Gradient Boosting\" and it is an implementation of gradient boosting trees algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xGBR = XGBRegressor().fit(X_train,y_train)\n",
    "predicted = xGBR.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBRegressor prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.sqrt(mean_squared_error(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor\n",
    "A random forest is a meta estimator that fits a number of classifying decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR = RandomForestRegressor().fit(X_train,y_train)\n",
    "predicted = RFR.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor predicion accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.sqrt(mean_squared_error(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparametere tuning\n",
    "First we perform standardization on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "  remainder=\"passthrough\",\n",
    "  transformers=[\n",
    "    (\"scale\", StandardScaler(), selector(dtype_include=\"number\")),\n",
    "    (\"one-hot\", OneHotEncoder(), selector(dtype_include=\"object\"))\n",
    "  ])\n",
    "\n",
    "X_train_encoded = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBRegressor parameters\n",
    "The most commonly configured hyperparameters are the following:\n",
    "- n_estimators: The number of trees, often increased until no further improvements are seen.\n",
    "- max_depth: The maximum depth of each tree, often values are between 1 and 10.\n",
    "- eta: The learning rate used to weight each model, often set to small values such as 0.3, 0.1, 0.01, or smaller.\n",
    "- subsample: The number of samples (rows) used in each tree, set to a value between 0 and 1, often 1.0 to use all samples.\n",
    "- colsample_bytree: Number of features (columns) used in each tree, set to a value between 0 and 1, often 1.0 to use all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "XGB_model = XGBRegressor()\n",
    "\n",
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=123)\n",
    "\n",
    "# define loss function\n",
    "loss = 'neg_mean_absolute_error'\n",
    "\n",
    "# evaluate the model\n",
    "scores = cross_val_score(XGB_model, X_test, y_test, scoring=loss, cv=cv, n_jobs=-1)\n",
    "\n",
    "# get positive scores\n",
    "scores = abs(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the best hyperparameter combination, we perform grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create grid of hyperparameter values\n",
    "hyper_grid = {\n",
    "  'n_estimator': (3, 5, 7, 9),\n",
    "  'max_depth': (4, 5, 6, 7),\n",
    "  'eta': (0.3, 0.1, 0.001)\n",
    "  }\n",
    "\n",
    "# create 10 fold CV object\n",
    "kfold = KFold(n_splits=10, random_state=123, shuffle=True)\n",
    "\n",
    "# perform grid search\n",
    "grid_search = GridSearchCV(XGB_model, hyper_grid, cv=kfold, scoring=loss)\n",
    "results = grid_search.fit(X_train_encoded, y_train)\n",
    "\n",
    "# show the best estimator\n",
    "results.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor parameters\n",
    "The most commonly configured hyperparameters are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "RFR_model = RandomForestRegressor()\n",
    "\n",
    "hyper_grid = {\n",
    " 'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
    "}\n",
    "\n",
    "# create 5 fold CV object\n",
    "kfold = KFold(n_splits=5, random_state=123, shuffle=True)\n",
    "\n",
    "# perform grid search\n",
    "grid_search = GridSearchCV(RFR_model, hyper_grid, cv=kfold, scoring=loss)\n",
    "results = grid_search.fit(X_train_encoded, y_train)\n",
    "\n",
    "# show the best estimator\n",
    "results.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ML_DS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d216e108d1e253960a691f297498892bdf5023c62959a45046f60e7d498f434e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
